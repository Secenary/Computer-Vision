{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7311abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# 数据预处理（标准化 + 数据增强）\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet标准化\n",
    "])\n",
    "\n",
    "# 加载PASCAL VOC 2012数据集（仅需图像和语义分割mask）\n",
    "voc_train = datasets.VOCSegmentation(\n",
    "    root='./data', year='2012', image_set='train',\n",
    "    transform=transform, target_transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "voc_val = datasets.VOCSegmentation(\n",
    "    root='./data', year='2012', image_set='val',\n",
    "    transform=transform, target_transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "# 划分训练集、验证集、测试集（按7:2:1比例）\n",
    "train_loader = DataLoader(voc_train, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(voc_val, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(voc_val, batch_size=8, shuffle=False)  # 测试集直接使用验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c38d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class LightWeightSegmentation(nn.Module):\n",
    "    def __init__(self, num_classes=21):  # PASCAL VOC 21个类别（含背景）\n",
    "        super(LightWeightSegmentation, self).__init__()\n",
    "        # 使用预训练ResNet18作为编码器\n",
    "        resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.encoder = nn.Sequential(*list(resnet.children())[:-2])  # 去除最后两层\n",
    "        \n",
    "        # 解码器（上采样+卷积）\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, num_classes, kernel_size=2, stride=2)  # 输出类别数\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)  # 编码器输出特征图\n",
    "        x = self.decoder(x)  # 解码器还原到输入尺寸\n",
    "        return x\n",
    "\n",
    "model = LightWeightSegmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2aeff40",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'IoU' from 'torchmetrics' (C:\\Users\\Change\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchmetrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IoU\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 超参数\u001b[39;00m\n\u001b[0;32m      5\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255\u001b[39m)  \u001b[38;5;66;03m# 忽略无效标签\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'IoU' from 'torchmetrics' (C:\\Users\\Change\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchmetrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torchmetrics import IoU\n",
    "\n",
    "# 超参数\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=255)  # 忽略无效标签\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "num_epochs = 10\n",
    "\n",
    "# 训练函数\n",
    "def train(model, dataloader, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, masks in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks.squeeze(1))  # 掩码需要压缩通道维度\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch} Train Loss: {total_loss/len(dataloader)}\")\n",
    "\n",
    "# 验证函数（计算IoU和准确率）\n",
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    iou_metric = IoU(num_classes=21)\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            iou_metric.update(preds, masks.squeeze(1))\n",
    "            correct += (preds == masks.squeeze(1)).sum().item()\n",
    "            total += masks.numel()\n",
    "    print(f\"Validation Accuracy: {correct/total:.4f}, IoU: {iou_metric.compute():.4f}\")\n",
    "\n",
    "# 开始训练\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(model, train_loader, epoch)\n",
    "    validate(model, val_loader)\n",
    "    scheduler.step()\n",
    "\n",
    "# 测试集最终评估\n",
    "validate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a8cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_predictions(model, dataloader, num_samples=3):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            for i in range(num_samples):\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.title(\"Input Image\")\n",
    "                plt.imshow(images[i].permute(1, 2, 0).cpu().numpy())\n",
    "                \n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.title(\"True Mask\")\n",
    "                plt.imshow(masks[i].squeeze().cpu().numpy(), cmap='gray')\n",
    "                \n",
    "                plt.subplot(1, 3, 3)\n",
    "                plt.title(\"Predicted Mask\")\n",
    "                plt.imshow(preds[i].cpu().numpy(), cmap='gray')\n",
    "                plt.show()\n",
    "            break\n",
    "\n",
    "visualize_predictions(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
